{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_csv = pd.read_csv('/kaggle/input/movielens-20m-dataset/movie.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_csv= pd.read_csv('/kaggle/input/movielens-20m-dataset/tag.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "movieid = defaultdict(list)\n",
    "for i in range(0,len(tags_csv)):\n",
    "    movieid[tags_csv['movieId'].iloc[i]].append(str(tags_csv['tag'].iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieidslist = []\n",
    "moviemap = defaultdict()\n",
    "j = 0\n",
    "for key,values in movieid.items():\n",
    "    movieidslist.append((' ').join(values))\n",
    "    moviemap[key] = j\n",
    "    j =j+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviemap\n",
    "moviemapreverse = defaultdict(list)\n",
    "for key,value in moviemap.items():\n",
    "    moviemapreverse[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features  = 3000)\n",
    "vectors = vectorizer.fit_transform(movieidslist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting features using autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Dense,Embedding,Input,Flatten,Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getmodel(latent_factors,features):\n",
    "    model = models.Sequential()\n",
    "    model.add(Dense(4096,activation = 'relu', input_shape=(24111,)))\n",
    "    model.add(Dense(1024,activation = 'relu'))\n",
    "    model.add(Dense(512,activation= 'relu'))\n",
    "    model.add(Dense(128,activation = 'relu'))\n",
    "    model.add(Dense(latent_factors,activation = 'relu'))\n",
    "    model.add(Dense(128,activation = 'relu'))\n",
    "    model.add(Dense(256,activation = 'relu'))\n",
    "    model.add(Dense(1024,activation = 'relu'))\n",
    "    model.add(Dense(4096,activation = 'relu'))\n",
    "    model.add(Dense(features,activation = 'sigmoid'))\n",
    "    return model\n",
    "                    \n",
    "def getmodel1(latent_factors, features):\n",
    "    inp1 = Input(shape=(features,))\n",
    "    #d1 = Dense(4096, activation='relu')(inp1)\n",
    "    #d1 = Dropout(0.3)(d1)\n",
    "    #d1 = Dense(1024, activation='relu')(inp1)\n",
    "    #d1 = Dense(512, activation='relu')(inp1)\n",
    "    #d1 = Dense(128, activation='relu')(d1)\n",
    "    d1 = Dense(latent_factors, activation='relu')(inp1)\n",
    "   #d1 = Dense(128, activation='relu')(d1)\n",
    "    #d1 = Dense(512, activation='tanh')(d1)\n",
    "    #d1 = Dense(1024, activation='relu')(d1)\n",
    "    #|d1 = Dense(4096, activation='relu')(d1)\n",
    "    d1 = Dense(features, activation='sigmoid')(d1)\n",
    "    model = Model(inputs=inp1, outputs=d1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectors.shape)\n",
    "features = vectors.shape[1]\n",
    "#print(features.shape)\n",
    "#features = features.reshape(-1,)\n",
    "latentfactors = 32\n",
    "model = getmodel1(latentfactors,features)\n",
    "model.compile(loss = 'binary_crossentropy',optimizer = Adam(0.01),metrics = ['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autoencoder = model.fit(array,array,epochs = 1,validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/kaggle/working/model_autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modell = models.Sequential()\n",
    "count = 0\n",
    "for i in model.layers:\n",
    "    if(count<2):\n",
    "        modell.add(i)\n",
    "    count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modell.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getinfo(x):\n",
    "    iid = getid(x)\n",
    "    moviename = np.where(movie_csv['movieId'] == iid)\n",
    "    moviename = list(moviename)[0]\n",
    "    moviename = moviename[0]\n",
    "    print(\"movie_name :{}\".format(movie_csv.iloc[moviename]))\n",
    "    print('\\n Movie descriptions: {}'.format(movieidslist[x]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "a.append(movieidslist[875])\n",
    "#getinfo(875)\n",
    "vector_item = vectorizer.transform(a)\n",
    "ans = modell.predict(vector_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = []\n",
    "b.append(movieidslist[87])\n",
    "#getinfo(87)\n",
    "vector_items1 = vectorizer.transform(b)\n",
    "ansa = modell.predict(vector_items1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = cosine_similarity(ans,ansa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosines = []\n",
    "for i in predictlistvectors:\n",
    "    sim = cosine_similarity(ans,i)\n",
    "    cosines.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "cosines_id = []\n",
    "for i,j in enumerate(cosines):\n",
    "    cosines_id.append([i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keysort(cosine_id):\n",
    "    return cosine_id[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosines_id.sort(reverse= True,key = keysort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cosines_id[0:10]:\n",
    "    getinfo(i[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
