{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bHZBFaUM-Kr"
   },
   "source": [
    "Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dRjA_J6_M5_Y"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeNelynENmo9"
   },
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZVa0jTbNOnq",
    "outputId": "fb21772b-3f5e-414d-9353-54b40943057c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is being imported. =====>\n"
     ]
    }
   ],
   "source": [
    "print('The dataset is being imported. =====>')\n",
    "movies = pd.read_csv('/content/drive/MyDrive/SWM/ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "users = pd.read_csv('/content/drive/MyDrive/SWM/ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "ratings = pd.read_csv('/content/drive/MyDrive/SWM/ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ve8yI_mvbNdz"
   },
   "source": [
    "Preparing the training set and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bgqMzLiqXSlp",
    "outputId": "19eea83c-6101-4bec-bd8b-95ac31e70e82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the train and test datasets =====>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          0     1  2          3\n",
       "0        1     1  5  874965758\n",
       "1        1     2  3  876893171\n",
       "2        1     3  4  878542960\n",
       "3        1     4  3  876893119\n",
       "4        1     5  3  889751712\n",
       "...    ...   ... ..        ...\n",
       "79995  943  1067  2  875501756\n",
       "79996  943  1074  4  888640250\n",
       "79997  943  1188  3  888640250\n",
       "79998  943  1228  3  888640275\n",
       "79999  943  1330  3  888692465\n",
       "\n",
       "[80000 rows x 4 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Creating the train and test datasets =====>')\n",
    "# Training and test set for 100k users\n",
    "tr_df = pd.read_csv('/content/drive/MyDrive/SWM/ml-100k/u1.base', delimiter = '\\t', header=None)\n",
    "test_set_df = pd.read_csv('/content/drive/MyDrive/SWM/ml-100k/u1.test', delimiter = '\\t', header=None)\n",
    "tr_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dfn5Wde4XXuX"
   },
   "outputs": [],
   "source": [
    "# Convert training set and test set in numpy arrays\n",
    "training_set_ar = np.array(tr_df, dtype = 'int')\n",
    "test_set_ar = np.array(test_set_df, dtype = 'int')\n",
    "# Getting the number of users and movies\n",
    "nb_users = int(max(max(training_set_ar[:,0]), max(test_set_ar[:,0])))\n",
    "nb_movies = int(max(max(training_set_ar[:,1]), max(test_set_ar[:,1])))\n",
    "nb_userAttributes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "WsjAyInXts7V"
   },
   "outputs": [],
   "source": [
    "users['female_user'] = (users[1] == 'F').astype(int)\n",
    "users['male_user'] = (users[1] == 'M').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZgcMFt9mvtW4"
   },
   "source": [
    "Extract unique genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sHOlrjzyvhMR",
    "outputId": "8c764613-ff38-491b-fff7-ce7a38cc7e49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting unique genres =====>\n",
      "['Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "# extract unique genre values\n",
    "print('Extracting unique genres =====>')\n",
    "genre = movies[2]\n",
    "unique_genre = genre.unique()\n",
    "genre_values = []\n",
    "for movie_genre in unique_genre:\n",
    "    mg = movie_genre.split(\"|\")\n",
    "    for g in mg:\n",
    "        if g not in genre_values:\n",
    "            genre_values.append(g)\n",
    "            \n",
    "genre_values = sorted(genre_values, key=str.lower)\n",
    "print(genre_values)\n",
    "print(len(genre_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6dMLwUKwXKI"
   },
   "source": [
    "Create Genre Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zDb4jObKwA_S",
    "outputId": "88f7b1a4-7ceb-4ecb-edfc-5f63408adf6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# get genre vector\n",
    "def get_genre_vector(genre_row_val):\n",
    "    mg = genre_row_val.split(\"|\")\n",
    "    gen_vec = np.zeros(len(genre_values))\n",
    "    gen_index = 0\n",
    "    for g in genre_values:\n",
    "        if g in mg:\n",
    "            gen_vec[gen_index] = 1\n",
    "        gen_index += 1\n",
    "    return gen_vec\n",
    "# unit tests for above function\n",
    "print(get_genre_vector(\"Action|Adventure|Romance\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhM8n--XxXxX"
   },
   "source": [
    "Add Genre Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wN0VdFBwbu3",
    "outputId": "eb0a5d03-568c-476d-cd3b-a644061665ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Genre vector on movies df ====>\n"
     ]
    }
   ],
   "source": [
    "# Add Genre Vector to movies dataframe\n",
    "print('Creating Genre vector on movies df ====>')\n",
    "movie_data = movies[2]\n",
    "movie_col = []\n",
    "gen_index = 0\n",
    "for movie_gen in movie_data:\n",
    "    gen_vec = get_genre_vector(movie_gen)\n",
    "    movie_col.append(gen_vec)\n",
    "    gen_index += 1\n",
    "    \n",
    "movies['genre_vector'] = movie_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9hI9TFCys5n"
   },
   "source": [
    "Add genre vectors to training and testing dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YdONjG0ZyIO0",
    "outputId": "f73e2197-a72a-4168-995e-58c68b25ac4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Genre Vector to training and testing datasets =====>\n"
     ]
    }
   ],
   "source": [
    "def addgenrevector(data):\n",
    "    genre_array = []\n",
    "    movie_id_list = data[1].tolist()\n",
    "    for movie_id in movie_id_list:\n",
    "        genre_array.append(movies.loc[movies[0] == movie_id]['genre_vector'])\n",
    "    data['genre_vector'] = genre_array\n",
    "    return data\n",
    "        \n",
    "print('Adding Genre Vector to training and testing datasets =====>')\n",
    "training_set_gen_df = addgenrevector(tr_df)\n",
    "training_set_gen_ar = np.array(training_set_gen_df)\n",
    "test_set_gen_df = addgenrevector(test_set_df)\n",
    "test_set_gen_ar = np.array(test_set_gen_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GqH99Pe1Tki"
   },
   "source": [
    "Create the 2D data array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B1l0Uy2LzkFj",
    "outputId": "c2aed510-c49c-4ad7-b4f4-4764fa9290cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 2D matrix ======>\n",
      "(80000, 5)\n",
      "(20000, 5)\n"
     ]
    }
   ],
   "source": [
    "def createmultidimensionalmatrix(data):\n",
    "    print(data.shape)\n",
    "    gen_data = []\n",
    "    for id_users in range(1, nb_users + 1):\n",
    "        id_movies = data[1][data[0] == id_users]\n",
    "        id_ratings = data[2][data[0] == id_users]\n",
    "        user_genre_list = data['genre_vector'][data[0] == id_users][data[2] >= 3]\n",
    "        female_user = float(users['female_user'][users[0] == id_users])\n",
    "        male_user = float(users['male_user'][users[0] == id_users])\n",
    "        user_age = float(users[2][users[0] == id_users])\n",
    "        reg_months = float(users[3][users[0] == id_users])\n",
    "        user_genre_sum = np.zeros(len(genre_values))\n",
    "        for usr_gen_vec in user_genre_list:\n",
    "            if len(usr_gen_vec):\n",
    "                user_genre_sum = user_genre_sum + np.array(usr_gen_vec)\n",
    "        data_reshaped = np.zeros(nb_movies)\n",
    "        # Create a matrix with users in rows and ratings for each movie in columns\n",
    "        data_reshaped[id_movies - 1] = id_ratings\n",
    "        # Add columns of user genre only for good ratings\n",
    "        if user_genre_sum[0].shape:\n",
    "            data_reshaped = np.append(data_reshaped, user_genre_sum[0])\n",
    "        else:\n",
    "            data_reshaped = np.append(data_reshaped, user_genre_sum)\n",
    "            \n",
    "        data_reshaped = np.append(data_reshaped, [female_user])\n",
    "        data_reshaped = np.append(data_reshaped, [male_user])\n",
    "        data_reshaped = np.append(data_reshaped, [user_age])\n",
    "        data_reshaped = np.append(data_reshaped, [reg_months])\n",
    "        gen_data.append(list(data_reshaped))\n",
    "    return gen_data\n",
    "        \n",
    "        \n",
    "print('Creating 2D matrix ======>')    \n",
    "training_gen_data = createmultidimensionalmatrix(training_set_gen_df)\n",
    "test_gen_data = createmultidimensionalmatrix(test_set_gen_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bomNt4rw2pZF"
   },
   "source": [
    "Convert 2D array to torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O2XSRs-X1cm6",
    "outputId": "a0997f6a-555b-47c0-d45e-fe6f27d1d179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating torch tensors ======>\n"
     ]
    }
   ],
   "source": [
    "# Converting the data into Torch tensors\n",
    "print('Creating torch tensors ======>')\n",
    "training_set_1 = torch.FloatTensor(training_gen_data)\n",
    "test_set_1 = torch.FloatTensor(test_gen_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jEpAwr7K3n1x"
   },
   "outputs": [],
   "source": [
    "input_columns = len(training_gen_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZBZgMqU22v-"
   },
   "source": [
    "Build the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "PZ4Wnq4d2tpQ"
   },
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_columns, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10, 20)\n",
    "        self.fc4 = nn.Linear(20, input_columns)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "sae = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr=0.01, weight_decay=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOxcydQr4iw4"
   },
   "source": [
    "Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WVgldti825pl",
    "outputId": "34bef1ba-7693-4d31-a83a-a367a6461ad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: tensor(0.8662)\n",
      "epoch: 2 loss: tensor(0.8662)\n",
      "epoch: 3 loss: tensor(0.8661)\n",
      "epoch: 4 loss: tensor(0.8663)\n",
      "epoch: 5 loss: tensor(0.8659)\n",
      "epoch: 6 loss: tensor(0.8661)\n",
      "epoch: 7 loss: tensor(0.8660)\n",
      "epoch: 8 loss: tensor(0.8660)\n",
      "epoch: 9 loss: tensor(0.8658)\n",
      "epoch: 10 loss: tensor(0.8661)\n",
      "epoch: 11 loss: tensor(0.8658)\n",
      "epoch: 12 loss: tensor(0.8660)\n",
      "epoch: 13 loss: tensor(0.8656)\n",
      "epoch: 14 loss: tensor(0.8658)\n",
      "epoch: 15 loss: tensor(0.8655)\n",
      "epoch: 16 loss: tensor(0.8657)\n",
      "epoch: 17 loss: tensor(0.8654)\n",
      "epoch: 18 loss: tensor(0.8654)\n",
      "epoch: 19 loss: tensor(0.8652)\n",
      "epoch: 20 loss: tensor(0.8653)\n",
      "epoch: 21 loss: tensor(0.8651)\n",
      "epoch: 22 loss: tensor(0.8651)\n",
      "epoch: 23 loss: tensor(0.8644)\n",
      "epoch: 24 loss: tensor(0.8645)\n",
      "epoch: 25 loss: tensor(0.8642)\n",
      "epoch: 26 loss: tensor(0.8656)\n",
      "epoch: 27 loss: tensor(0.8651)\n",
      "epoch: 28 loss: tensor(0.8646)\n",
      "epoch: 29 loss: tensor(0.8647)\n",
      "epoch: 30 loss: tensor(0.8645)\n",
      "epoch: 31 loss: tensor(0.8644)\n",
      "epoch: 32 loss: tensor(0.8646)\n",
      "epoch: 33 loss: tensor(0.8646)\n",
      "epoch: 34 loss: tensor(0.8642)\n",
      "epoch: 35 loss: tensor(0.8644)\n",
      "epoch: 36 loss: tensor(0.8645)\n",
      "epoch: 37 loss: tensor(0.8644)\n",
      "epoch: 38 loss: tensor(0.8643)\n",
      "epoch: 39 loss: tensor(0.8642)\n",
      "epoch: 40 loss: tensor(0.8644)\n",
      "epoch: 41 loss: tensor(0.8643)\n",
      "epoch: 42 loss: tensor(0.8644)\n",
      "epoch: 43 loss: tensor(0.8644)\n",
      "epoch: 44 loss: tensor(0.8641)\n",
      "epoch: 45 loss: tensor(0.8641)\n",
      "epoch: 46 loss: tensor(0.8640)\n",
      "epoch: 47 loss: tensor(0.8637)\n",
      "epoch: 48 loss: tensor(0.8639)\n",
      "epoch: 49 loss: tensor(0.8635)\n",
      "epoch: 50 loss: tensor(0.8637)\n",
      "Average loss: tensor(7.3857)\n",
      "test loss: tensor(0.3916)\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 50\n",
    "for epoch in range(1, nb_epoch+1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_user in range(nb_users):\n",
    "        input = Variable(training_set_1[id_user]).unsqueeze(0)\n",
    "        target = input.clone()\n",
    "        #Select only rating related columns to compute loss\n",
    "        target_ratings = target[:, :nb_movies]\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            output = sae(input)\n",
    "            output_ratings = output[:, :nb_movies]\n",
    "            target.require_grad = False\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output_ratings, target_ratings)\n",
    "            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "            loss.backward()\n",
    "            train_loss += np.sqrt(loss.data*mean_corrector)\n",
    "            s += 1.\n",
    "            optimizer.step()\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n",
    "    \n",
    "    \n",
    "# Testing the SAE\n",
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(nb_users):\n",
    "    input = Variable(training_set_1[id_user]).unsqueeze(0)\n",
    "    target = Variable(test_set_1[id_user]).unsqueeze(0)\n",
    "    target_ratings = target[:, :nb_movies]\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "        output = sae(input)\n",
    "        output_ratings = output[:, :nb_movies]\n",
    "        target.require_grad = False\n",
    "        output[target == 0] = 0\n",
    "        loss = criterion(output_ratings, target_ratings)\n",
    "        mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += np.sqrt(loss.data*mean_corrector)\n",
    "        s += 1.\n",
    "print('Average loss: '+str(test_loss/nb_epoch))\n",
    "print('test loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmGZzXoG4lN-",
    "outputId": "6b5f8871-f821-40aa-a0f9-4d8a8e6c4bcf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.8531,  3.5427,  3.0489,  ..., -0.0141,  0.0141, -0.0047],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = Variable(training_set_1[0]).unsqueeze(0)\n",
    "sae(training_set_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "DAsJd7YUDFVP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "AutoRec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
